panel.background = element_rect(colour = NA),
plot.background = element_rect(colour = NA),
panel.border = element_rect(colour = NA),
axis.title = element_text(face = "bold",size = rel(1)),
axis.title.y = element_text(angle=90,vjust =2),
axis.title.x = element_text(vjust = -0.2),
axis.text = element_text(),
axis.line = element_line(colour="black"),
axis.ticks = element_line(),
panel.grid.major = element_line(colour="#f0f0f0"),
panel.grid.minor = element_blank(),
legend.key = element_rect(colour = NA),
legend.position = "bottom",
legend.direction = "horizontal",
#legend.key.size= unit(0.2, "cm"),
legend.margin = unit(0, "cm"),
legend.title = element_text(face="italic"),
plot.margin=unit(c(10,5,5,5),"mm"),
strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
strip.text = element_text(face="bold")
))
}
scale_fill_Publication <- function(...){
library(scales)
discrete_scale("fill","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
scale_colour_Publication <- function(...){
library(scales)
discrete_scale("colour","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
wrap_labels <- function(labels, width = 5) {
wrapped_labels <- str_wrap(labels, width)
names(wrapped_labels) <- names(labels)
return(wrapped_labels)
}
hg19_size <- 3036303846
vep_cols <- c("Uploaded_variation", "Location", "Allele", "Gene", "Feature", "Feature_type", "Consequence", "cDNA_position", "CDS_position", "Protein_position", "Amino_acids", "Codons", "Existing_variation", "IMPACT", "DISTANCE", "STRAND", "FLAGS", "VARIANT_CLASS", "SYMBOL", "SYMBOL_SOURCE", "HGNC_ID", "BIOTYPE", "CANONICAL", "MANE_SELECT", "MANE_PLUS_CLINICAL", "TSL", "APPRIS", "CCDS", "ENSP", "SWISSPROT", "TREMBL", "UNIPARC", "UNIPROT_ISOFORM", "SOURCE", "GENE_PHENO", "SIFT", "PolyPhen", "EXON", "INTRON", "DOMAINS", "miRNA", "HGVSc", "HGVSp", "HGVS_OFFSET", "AF", "AFR_AF", "AMR_AF", "EAS_AF", "EUR_AF", "SAS_AF", "gnomADe_AF", "gnomADe_AFR_AF", "gnomADe_AMR_AF", "gnomADe_ASJ_AF", "gnomADe_EAS_AF", "gnomADe_FIN_AF", "gnomADe_NFE_AF", "gnomADe_OTH_AF", "gnomADe_SAS_AF", "gnomADg_AF", "gnomADg_AFR_AF", "gnomADg_AMI_AF", "gnomADg_AMR_AF", "gnomADg_ASJ_AF", "gnomADg_EAS_AF", "gnomADg_FIN_AF", "gnomADg_MID_AF", "gnomADg_NFE_AF", "gnomADg_OTH_AF", "gnomADg_SAS_AF", "MAX_AF", "MAX_AF_POPS", "CLIN_SIG", "SOMATIC", "PHENO", "PUBMED", "MOTIF_NAME", "MOTIF_POS", "HIGH_INF_POS", "MOTIF_SCORE_CHANGE", "TRANSCRIPTION_FACTORS", "CADD_PHRED", "CADD_RAW", "am_class", "am_pathogenicity", "BLOSUM62", "CAROL", "mutfunc_motif", "5UTR_annotation", "5UTR_consequence", "Existing_InFrame_oORFs", "Existing_OutOfFrame_oORFs", "Existing_uORFs", "NMD", "GERP", "phastCons", "phyloP")
# Chunk 4
vep_files <- list.files(path = "/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/vep/",
pattern = "\\.txt$", full.names = TRUE)
sample_table <- read.table("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
# reorder vep_files to match sample_table
vep_files <- vep_files[match(sample_table$sample,tools::file_path_sans_ext(basename(vep_files)))]
# read in files to list
vep_list <- lapply(vep_files, function(x) read.table(x, comment.char = "#", fill = TRUE, sep = "\t"))
# names
names(vep_list) <- sample_table$sample
# add column names
vep_list <- lapply(vep_list, function(df) {
colnames(df) <- vep_cols
return(df)
})
# filter for SNV
vep_list <- lapply(vep_list, function(df) {
df <- subset(df, VARIANT_CLASS == "SNV")
return(df)
})
# Chunk 5
vep_list_condition <- list(control = do.call(rbind, vep_list[sample_table$condition == "control"]),
enu = do.call(rbind, vep_list[sample_table$condition == "enu"]))
vep_shuffle <- list.files(path = "/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/vep/simulated_cell_burden-matched/",
pattern = "\\.txt$", full.names = TRUE)
# create a table for the shuffled samples
shuffle_table <- sample_table[0, ]
for (i in 1:nrow(sample_table)) {
replicatedRow <- sample_table[rep(i, 100), ]
shuffle_table <- rbind(shuffle_table, replicatedRow)
}
vep_shuffle
vep_shuffle <- list.files(path = "/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/vep/simulated_cell_burden-matched",
pattern = "\\.txt$", full.names = TRUE)
# create a table for the shuffled samples
shuffle_table <- sample_table[0, ]
for (i in 1:nrow(sample_table)) {
replicatedRow <- sample_table[rep(i, 100), ]
shuffle_table <- rbind(shuffle_table, replicatedRow)
}
vep_shuffle
shuffle_table
shuffle_table$sample <- as.vector(unlist(sapply(sample_table$sample, function(x) {paste0(x, "_", 1:100)})))
shuffle_table
# reorder vep_files to match shuffle_table
vep_shuffle <- vep_shuffle[match(shuffle_table$sample,tools::file_path_sans_ext(basename(vep_shuffle)))]
# load
vep_shuffle_list <- lapply(vep_shuffle, function(x) read.table(x, comment.char = "#", fill = TRUE, sep = "\t"))
library(DESeq2)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(ggpubr)
library(ComplexHeatmap)
library(corrplot)
library(maditr)
library(reshape2)
library(dplyr)
library(PCAtools)
library(stringr)
library(NbClust)
library(factoextra)
colour = palette.colors(palette = "Okabe-Ito")
# Chunk 3
all_un <- function(str) {
matches <- gregexpr("\\[.*?\\]", str)
brackets <- regmatches(str, matches)[[1]]
all(grepl("\\[un\\]", brackets))
}
unmod <- function(peptide) {
# Split the peptide by the semicolon
marks <- strsplit(peptide, ";")[[1]]
# Check if all the modifications are [un]
all_un <- all(grepl("\\[un\\]", marks))
return(all_un)
}
single_mark <- function(peptide) {
# Split the peptide by the semicolon
marks <- strsplit(peptide, ";")[[1]]
# Count the number of modifications (excluding [un])
modification_count <- sum(!grepl("\\[[un]\\]", marks))
# Check if it's exactly one
return(modification_count == 1)
}
combination_marks <- function(peptide) {
# Split the peptide by the semicolon
marks <- strsplit(peptide, ";")[[1]]
# Extract all the marks within brackets that are not [un]
unique_marks <- unique(gregexpr("\\[[^un]\\w+\\]", peptide, perl = TRUE)[[1]])
# Check if there are at least 2 unique marks other than [un]
return(length(unique_marks) >= 2)
}
hybrid_marks <- function(peptide) {
ac <- grepl("\\[ac\\]", peptide)
me <- grepl("\\[me1\\]", peptide) |
grepl("\\[me2\\]", peptide) |
grepl("\\[me3\\]", peptide)
return(ac && me)
}
BiocManager::install("SummarizedExperiment")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("SummarizedExperiment")
BiocManager::install("SummarizedExperiment")
library(SummarizedExperiment)
knitr::opts_chunk$set(echo = TRUE)
install.packages("knitr")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
install.packages("readxl")
library(readxl)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Collaboration/April\ Mueller/1-data")
unlink("Dropbox (EinsteinMed)/Sidoli-lab/Collaboration/April Mueller/2-histone-analysis/differential-abundance_cache", recursive = TRUE)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Collaboration/April\ Mueller/1-data")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
setwd("/Users/ronaldcutler/Dropbox\ \(EinsteinMed\)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = TRUE)
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = FALSE)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = FALSE)
?read.table
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = FALSE,
fill = NA)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = FALSE,
fill = NA)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = TRUE,
fill = NA)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
header = FALSE,
fill = NA)
head(df)
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Sidoli-lab/Projects/Single-cell-histone/Analysis/1-data/single-cell/spectronaut")
df <- read.table("20240129_162957_Histone_VarPropK_Report.tsv",
sep = "\t",
header = TRUE,
fill = NA)
head(df)
colnames(df)
df %>%
group_by(R.FileName)
df %>%
group_by(R.FileName) %>%
count(PG.Genes)
df %>%
group_by(R.FileName) %>%
count(PG.Genes)
df %>%
group_by(R.FileName)
df %>%
group_by(R.FileName)
df %>%
group_by(R.FileName) %>%
count(PG.Genes)
df %>%
group_by(R.FileName) %>%
count(unique(PG.Genes))
df %>%
group_by(R.FileName) %>%
count(PG.Genes) %>%
nrow()
df %>%
filter(!grepl(";", PG.Genes))
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
summarise(genes = count(PG.Genes))
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
summarise(genes = sum(PG.Genes))
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
count(PG.Genes)
df %>%
filter(!grepl(";", PG.Genes)) %>%
distinct(PG.Genes, .keep_all = TRUE)
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
distinct(PG.Genes, .keep_all = TRUE)
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
distinct(PG.Genes, .keep_all = TRUE) %>%
count(PG.Genes)
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
distinct(PG.Genes, .keep_all = TRUE)
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName)
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
count(PG.Genes)
df %>%
filter(!grepl(";", PG.Genes)) %>%
group_by(R.FileName) %>%
summarise(Genes = n_distinct(PG.Genes))
res <- readRDS("/Users/ronaldcutler/Dropbox\ \(EinsteinMed\)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/10-dnds-ratio/enu.res.list.RDS")
/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/10-dnds-ratio/enu.res.list.RDS
res <- readRDS("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/10-dnds-ratio/enu.res.list.RDS")
res
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(dplyr)
library(tibble)
library(ComplexHeatmap)
library(RUVSeq)
BiocManager::install("RUVSeq")
library(biomaRt)
library(msigdbr)
library(SummarizedExperiment)
library(DESeq2)
library(PCAtools)
library(genefilter)
library(zFPKM)
library(ggplot2)
library(ggrepel)
library(EnhancedVolcano)
library(ComplexHeatmap)
library(UpSetR)
log2(2)
exp(1)
?exp
2^-1
2^1
2^0.5
2^1
2^-0.237201877813034
2^-0.33
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(stringr)
library(dplyr)
library(ggpubr)
library(purrr)
library(rstatix)
library(emmeans)
library(viridis)
# Chunk 3
# sum similar variants
sum_and_replace_rows <- function(data, strings_to_match) {
# Initialize an empty dataframe with the same columns as the input data
result_data <- data.frame()
# Loop through each string to match
for (string_to_match in strings_to_match) {
# Define the pattern to match
pattern <- paste0("^", string_to_match)
# Filter and group the data
grouped_data <- data %>%
filter(grepl(pattern, variant_type)) %>%
group_by(sample, condition, cycle) %>%
summarise(obs.mut = sum(obs.mut), .groups = 'drop')
# Add the matched variant_type to the grouped data
grouped_data <- grouped_data %>%
mutate(variant_type = string_to_match)
# Append the grouped data to the result_data
result_data <- bind_rows(result_data, grouped_data)
# Remove the matched rows from the original data
data <- data %>%
filter(!grepl(pattern, variant_type))
}
# Bind the remaining original data to the result_data
result_data <- bind_rows(result_data, data)
return(result_data)
}
# combine the permutation pvalues from each sample
# to assess if group of samples is significantly different from expected
combine_pvalues_fisher <- function(p_values) {
chi_sq_stat = -2 * sum(log(p_values))
degrees_of_freedom = 2 * length(p_values)
p_combined = pchisq(chi_sq_stat, degrees_of_freedom, lower.tail = FALSE)
return(p_combined)
}
# function to calculate significance with results coming from
# observed and downsampled
ratio_significance <- function(ratios, group_vars) {
res <- ratios %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(pvalue = combine_pvalues_fisher(pvalue)) %>%
mutate(pvalue_symbol = case_when(
pvalue <= 0.0001 ~ '****',
pvalue <= 0.001 ~ '***',
pvalue <= 0.01 ~ '**',
pvalue <= 0.05 ~ '*',
TRUE ~ NA))
}
# function to calculate significance between condition groups
group_significance <- function(combined_regions, group_vars, condition, group_levels){
formula <- as.formula(paste("obs.mut ~", condition))
results <- combined_regions %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(
p_value = wilcox.test(formula = formula,
data = cur_data(),
exact = FALSE)$p.value
) %>%
ungroup() %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)
)
# Order by region
results$variant_type <- factor(results$variant_type, levels = group_levels)
return(results)
}
calculate_stat_summary <- function(observed, group_vars, mut_var){
results <- observed %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(mean = mean(!!sym(mut_var), na.rm = TRUE),
sd = sd(!!sym(mut_var), na.rm = TRUE))
}
theme_Publication <- function(base_size=16, base_family="helvetica") {
library(grid)
library(ggthemes)
(theme_foundation(base_size=base_size, base_family = "")
+ theme(plot.title = element_text(face = "bold",
size = rel(1.2), hjust = 0.5),
text = element_text(),
panel.background = element_rect(colour = NA),
plot.background = element_rect(colour = NA),
panel.border = element_rect(colour = NA),
axis.title = element_text(face = "bold",size = rel(1)),
axis.title.y = element_text(angle=90,vjust =2),
axis.title.x = element_text(vjust = -0.2),
axis.text = element_text(),
axis.line = element_line(colour="black"),
axis.ticks = element_line(),
panel.grid.major = element_line(colour="#f0f0f0"),
panel.grid.minor = element_blank(),
legend.key = element_rect(colour = NA),
legend.position = "bottom",
legend.direction = "horizontal",
#legend.key.size= unit(0.2, "cm"),
legend.margin = unit(0, "cm"),
legend.title = element_text(face="italic"),
plot.margin=unit(c(10,5,5,5),"mm"),
strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
strip.text = element_text(face="bold")
))
}
scale_fill_Publication <- function(...){
library(scales)
discrete_scale("fill","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
scale_fill_Publication_2 <- function(...){
library(scales)
discrete_scale("fill","Publication",manual_pal(values = c("#7fc97f","#ef3b2c","#386cb0","#fdb462","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
scale_colour_Publication <- function(...){
library(scales)
discrete_scale("colour","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
wrap_labels <- function(labels, width = 5) {
wrapped_labels <- str_wrap(labels, width)
names(wrapped_labels) <- names(labels)
return(wrapped_labels)
}
# Chunk 4
sample_table <- read.table("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
# Chunk 5
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/5-variant-effect-prediction/1-calculate-ratio/cells")
# consequences
consequences.main.mean <- read.csv("consequence_main_oe_mean.csv", header = TRUE, row.names = NULL)
# consequences.main.median <- read.csv("consequence_main_oe_mean.csv", header = TRUE, row.names = NULL)
# # consequences.sub.mean <- read.csv("observed_consequence_subtypes_ratio_mean.csv", header = TRUE, row.names = NULL)
# # consequences.sub.median <- read.csv("observed_consequence_subtypes_ratio_median.csv", header = TRUE, row.names = NULL)
consequences.syn_non.mean <- read.csv("consequence_synonymous_nonsynonymous_oe_mean.csv", header = TRUE, row.names = NULL)
# consequences.syn_non.median <- read.csv("observed_consequence_synonymous_nonsynonymous_ratio_median.csv", header = TRUE, row.names = NULL)
# alpha missense - score above 0.564 likely pathogenic. range 0-Inf
# use absolute
# am.mean <- read.csv("observed_alpha-missense_absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# am.median <- read.csv("observed_alpha-missense_absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# am.sum <- read.csv("observed_alpha-missense_absolute_ratio_sum.csv", header = TRUE, row.names = NULL)
# cadd - observed variant has negative values while simulated variant has positive values - more positive more damaging
# need to redo and classify into observed and simulated and then count
# classify into insertion and deletion
# use non-absolute
cadd.mean <- read.csv("cadd_phred_oe_mean.csv", header = TRUE, row.names = NULL)
# gerp - score above 2 indicates constrained site. Range from -12 to 6
# need to redo and classify into constrained and non and then count
# also need to prevent NA in control when calculating ratio
# use non-absolute and mean
# gerp.mean <- read.csv("observed_gerp_non-absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# gerp.median <- read.csv("observed_gerp_non-absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# transcription factor score change
# use absolute
# tf.mean <- read.csv("observed_tf_absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# tf.median <- read.csv("observed_tf_absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# tf.sum <- read.csv("observed_tf_absolute_ratio_sum.csv", header = TRUE, row.names = NULL)
# phyloP - conserved sites are positive and non-conserved are negative
# need to redo and classify into conserved and non-conserved and then count
# use non-absolute
# phylop.mean <- read.csv("observed_phylop_non-absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# phylop.median <- read.csv("observed_phylop_non-absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# phastcons - probability of negative selection from 0-1
# use non-absolute
# phastcons.mean <- read.csv("observed_phastCons_non-absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# phastcons.median <- read.csv("observed_phastCons_non-absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# phastcons.sum <- read.csv("observed_phastCons_non-absolute_ratio_sum.csv", header = TRUE, row.names = NULL)
# Chunk 6
consequences.main.mean <- merge(consequences.main.mean,
sample_table,
by = "sample")
print(consequences.main.mean %>%
group_by(variant_type) %>%
summarize(total = sum(obs.mut)),
n = Inf)
# print(consequences.syn_non.mean %>%
#   group_by(variant_type) %>%
#   summarize(total = sum(obs.mut)),
#   n = Inf)
# Chunk 7
consequences.main.mean <- consequences.main.mean %>%
mutate(mutation_type = case_when(
variant_type == "inframe insertion" ~ "INDEL",
variant_type == "inframe deletion" ~ "INDEL",
variant_type == "frameshift variant" ~ "INDEL",
.default = "SNV"
)
)
consequences.main.mean %>%
group_by(mutation_type) %>%
summarize(total = sum(obs.mut))
# Chunk 8
consequences.main.mean <- consequences.main.mean %>%
mutate(group = case_when(
variant_type == "synonymous variant" ~ "coding",
variant_type == "missense variant" ~ "coding",
variant_type == "start lost" ~ "coding",
variant_type == "stop gained" ~ "coding",
variant_type == "stop lost" ~ "coding",
variant_type == "splice acceptor variant" ~ "coding",
variant_type == "splice donor variant" ~ "coding",
variant_type == "inframe insertion" ~ "coding",
variant_type == "inframe deletion" ~ "coding",
variant_type == "frameshift variant" ~ "coding",
variant_type == "coding sequence variant / NMD transcript variant" ~ "coding",
variant_type == "synonymous variant / NMD transcript variant" ~ "coding",
.default = "non-coding"
)
)
consequences.main.mean %>%
group_by(group) %>%
summarize(total = sum(obs.mut))
1062/108132
1062/(108132+1062)*100
print(consequences.main.mean %>%
group_by(variant_type) %>%
summarize(total = sum(obs.mut)),
n = Inf)
51003/(108132+1062)*100
250/(108132+1062)*100
