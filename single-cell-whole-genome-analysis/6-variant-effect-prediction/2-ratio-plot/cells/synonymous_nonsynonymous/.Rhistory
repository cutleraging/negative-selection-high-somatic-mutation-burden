library(SummarizedExperiment)
library(biomaRt)
library(Seurat)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(VariantAnnotation)
library(GenomicRanges)
library(GenomicFeatures)
library(rtracklayer)
library(MutationalPatterns)
library(tibble)
library(foreach)
library(doParallel)
library(org.Hs.eg.db)
library(BSgenome.Hsapiens.UCSC.hg19)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
TxDb.Hsapiens.UCSC.hg19.knownGene <- keepStandardChromosomes(TxDb.Hsapiens.UCSC.hg19.knownGene)
TxDb.Hsapiens.UCSC.hg19.knownGene <- dropSeqlevels(TxDb.Hsapiens.UCSC.hg19.knownGene, c("chrY", "chrM"), pruning.mode="coarse")
hg19_size <- sum(seqlengths(TxDb.Hsapiens.UCSC.hg19.knownGene))
# sample_table <- read.table("/gs/gsfs0/users/vijg-lab/2023-Ronnie/231009_multiple_ENU_analysis/mutation-distribution/1-load-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
sample_table <- read.table("/Users/ronaldcutler/Dropbox\ \(EinsteinMed\)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-datasample_table_filtered.txt", header = TRUE, sep = "\t")
# sample_table <- read.table("/gs/gsfs0/users/vijg-lab/2023-Ronnie/231009_multiple_ENU_analysis/mutation-distribution/1-load-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
sample_table <- read.table("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-datasample_table_filtered.txt", header = TRUE, sep = "\t")
# sample_table <- read.table("/gs/gsfs0/users/vijg-lab/2023-Ronnie/231009_multiple_ENU_analysis/mutation-distribution/1-load-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
sample_table <- read.table("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
head(sample_table)
num_simulations <- 10000
sample_table_simulated <- sample_table[0, ]
for (i in 1:nrow(sample_table)) {
replicatedRow <- sample_table[rep(i, num_simulations), ]
sample_table_simulated <- rbind(sample_table_simulated, replicatedRow)
}
sample_table_simulated$sample_simulated <- as.vector(unlist(sapply(sample_table$sample, function(x) {paste0(x, "_", 1:num_simulations)})))
head(sample_table_simulated)
# break sample table into samples
sample_table_simulated_list <- split(sample_table_simulated, sample_table_simulated$sample)
head(sample_table_simulated_list)
head(sample_table_simulated_list)
?read_vcfs_as_granges
knitr::opts_chunk$set(echo = TRUE)
library(VariantAnnotation)
library(MutationalPatterns)
library(diann)
?readRDS
knitr::opts_chunk$set(echo = TRUE)
library(MutationalPatterns)
source("~/.active-rstudio-document", echo=TRUE)
length(vep_cols_observed)
knitr::opts_chunk$set(echo = TRUE)
vep_cols_observed <- c("Uploaded_variation", "Location", "Allele", "Gene", "Feature", "Feature_type", "Consequence", "cDNA_position", "CDS_position", "Protein_position", "Amino_acids", "Codons", "Existing_variation", "IMPACT", "DISTANCE", "STRAND", "FLAGS", "VARIANT_CLASS", "SYMBOL", "SYMBOL_SOURCE", "HGNC_ID", "BIOTYPE", "CANONICAL", "MANE_SELECT", "MANE_PLUS_CLINICAL", "TSL", "APPRIS", "CCDS", "ENSP", "SWISSPROT", "TREMBL", "UNIPARC", "UNIPROT_ISOFORM", "SOURCE", "GENE_PHENO", "SIFT", "PolyPhen", "EXON", "INTRON", "DOMAINS", "miRNA", "HGVSc", "HGVSp", "HGVS_OFFSET", "AF", "AFR_AF", "AMR_AF", "EAS_AF", "EUR_AF", "SAS_AF", "gnomADe_AF", "gnomADe_AFR_AF", "gnomADe_AMR_AF", "gnomADe_ASJ_AF", "gnomADe_EAS_AF", "gnomADe_FIN_AF", "gnomADe_NFE_AF", "gnomADe_OTH_AF", "gnomADe_SAS_AF", "gnomADg_AF", "gnomADg_AFR_AF", "gnomADg_AMI_AF", "gnomADg_AMR_AF", "gnomADg_ASJ_AF", "gnomADg_EAS_AF", "gnomADg_FIN_AF", "gnomADg_MID_AF", "gnomADg_NFE_AF", "gnomADg_OTH_AF", "gnomADg_SAS_AF", "MAX_AF", "MAX_AF_POPS", "CLIN_SIG", "SOMATIC", "PHENO", "PUBMED", "MOTIF_NAME", "MOTIF_POS", "HIGH_INF_POS", "MOTIF_SCORE_CHANGE", "TRANSCRIPTION_FACTORS", "CADD_PHRED", "CADD_RAW", "5UTR_annotation", "5UTR_consequence", "Existing_InFrame_oORFs", "Existing_OutOfFrame_oORFs", "Existing_uORFs", "NMD", "GERP", "phastCons", "phyloP")
length(vep_cols_observed)
install.packages(nortest)
install.packages("nortest")
knitr::opts_chunk$set(echo = TRUE)
library(nortest)
ad.test(c(3,234,5,3,2,6))
ad.test(c(3,234,5,3,2,6,3,2,5))
t <- ad.test(c(3,234,5,3,2,6,3,2,5))
t$p.value
vep_simulated_files
vep_cols_simulated <- c(
"Uploaded_variation", "Location", "Allele", "Gene", "Feature", "Feature_type",
"Consequence", "cDNA_position", "CDS_position", "Protein_position",
"Amino_acids", "Codons", "Existing_variation", "IMPACT", "DISTANCE",
"STRAND", "FLAGS", "VARIANT_CLASS", "SYMBOL", "SYMBOL_SOURCE", "HGNC_ID",
"BIOTYPE", "CANONICAL", "MANE_SELECT", "MANE_PLUS_CLINICAL", "TSL", "APPRIS",
"CCDS", "ENSP", "SWISSPROT", "TREMBL", "UNIPARC", "UNIPROT_ISOFORM",
"GENE_PHENO", "SIFT", "PolyPhen", "EXON", "INTRON", "DOMAINS", "miRNA",
"HGVSc", "HGVSp", "HGVS_OFFSET", "AF", "AFR_AF", "AMR_AF", "EAS_AF",
"EUR_AF", "SAS_AF", "gnomADe_AF", "gnomADe_AFR_AF", "gnomADe_AMR_AF",
"gnomADe_ASJ_AF", "gnomADe_EAS_AF", "gnomADe_FIN_AF", "gnomADe_NFE_AF",
"gnomADe_OTH_AF", "gnomADe_SAS_AF", "gnomADg_AF", "gnomADg_AFR_AF",
"gnomADg_AMI_AF", "gnomADg_AMR_AF", "gnomADg_ASJ_AF", "gnomADg_EAS_AF",
"gnomADg_FIN_AF", "gnomADg_MID_AF", "gnomADg_NFE_AF", "gnomADg_OTH_AF",
"gnomADg_SAS_AF", "MAX_AF", "MAX_AF_POPS", "CLIN_SIG", "SOMATIC", "PHENO",
"PUBMED", "MOTIF_NAME", "MOTIF_POS", "HIGH_INF_POS", "MOTIF_SCORE_CHANGE",
"TRANSCRIPTION_FACTORS", "CADD_PHRED", "CADD_RAW"
)
length(vep_cols_simulated)
?apply
setwd("/gs/gsfs0/users/rcutler/vijg-lab/2023-Ronnie/231009_multiple_ENU_analysis/variant-effect-prediction")
?sprintf
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(stringr)
library(dplyr)
library(ggpubr)
library(purrr)
library(rstatix)
library(viridis)
library(tidyr)
library(emmeans)
# Chunk 3
# combine the permutation pvalues from each sample
# using fishers combined test statistic
combine_pvalues_fisher <- function(p_values) {
chi_sq_stat = -2 * sum(log(p_values), na.rm = TRUE)
degrees_of_freedom = 2 * length(p_values)
p_combined = pchisq(chi_sq_stat, degrees_of_freedom, lower.tail = FALSE)
return(p_combined)
}
consequences_combined_significance <- function(ratios, group_vars, group_levels) {
res <- ratios %>%
subset(variant_type %in% group_levels) %>%
mutate(pvalue = if_else(pvalue == 0, 0.0001, pvalue)) %>% # give values to very low pvalues that are 0
group_by_at(vars(one_of(group_vars))) %>%
summarise(p_value = combine_pvalues_fisher(pvalue)) %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)) %>%
ungroup()
return(res)
}
consequences_combined_significance_CADD <- function(ratios, group_vars, group_levels) {
res <- ratios %>%
mutate(pvalue = if_else(pvalue == 0, 0.001, pvalue)) %>% # give values to very low pvalues that are 0
group_by_at(vars(one_of(group_vars))) %>%
summarise(p_value = combine_pvalues_fisher(pvalue)) %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)) %>%
ungroup()
return(res)
}
consequences_group_significance <- function(ratios, group_vars, group_levels) {
res <- ratios %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(p_value = suppressWarnings(wilcox.test(log2fc, mu = 0)$p.value)) %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)) %>%
ungroup()
return(res)
}
score_combined_significance <- function(ratios, group_vars, group_levels) {
res <- ratios %>%
mutate(pvalue = if_else(pvalue == 0, 0.001, pvalue)) %>% # give values to very low pvalues that are 0
group_by_at(vars(one_of(group_vars))) %>%
summarise(p_value = combine_pvalues_fisher(pvalue)) %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)) %>%
ungroup()
return(res)
}
# function to calculate significance between condition groups
group_significance <- function(combined_regions, group_vars, condition, group_levels){
formula <- as.formula(paste("log2fc ~", condition))
results <- combined_regions %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(
p_value = wilcox.test(formula = formula,
data = cur_data(),
exact = FALSE)$p.value
) %>%
ungroup() %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)
)
# Order by region
results$variant_type <- factor(results$variant_type, levels = group_levels)
return(results)
}
ratio_significance_summarize <- function(ratios, group_vars, group_levels) {
res <- ratios %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(p_value = combine_pvalues_fisher(pvalue)) %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)) %>%
ungroup()
# Order by region
res$type <- factor(res$type, levels = group_levels)
return(res)
}
group_significance_summarize <- function(combined_regions, group_vars, condition, group_levels){
formula <- as.formula(paste("log2fc ~", condition))
results <- combined_regions %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(
p_value = wilcox.test(formula = formula,
data = cur_data(),
exact = FALSE)$p.value
) %>%
ungroup() %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)
)
# Order by region
results$type <- factor(results$type, levels = group_levels)
return(results)
}
calculate_dnds <- function(df, variant_types, sample_table) {
variant_type2 <- "synonymous variant" # Fixed variant type2
# Initialize an empty data frame to store results
all_variant_ratios <- data.frame()
for (variant_type1 in variant_types) {
# Filter and calculate dnds for observed mutations
variant.obs <- df %>%
filter(variant_type %in% c(variant_type1, variant_type2)) %>%
select(sample, variant_type, obs.mut) %>%
mutate(obs.mut = obs.mut + 1) %>%
spread(key = variant_type, value = obs.mut, fill = 1) %>%  # fill = 1 to handle cases with 0 count
mutate(dnds = !!sym(variant_type1) / !!sym(variant_type2),
variant_type = variant_type1) %>%
select(sample, dnds, variant_type)
# Combine results of this variant type with the results of previous ones
all_variant_ratios <- rbind(all_variant_ratios, variant.obs)
}
# Combine with meta data
all_variant_ratios <- merge(all_variant_ratios, sample_table, by = "sample")
return(all_variant_ratios)
}
calculate_dnds_ratio <- function(df, variant_types, sample_table) {
variant_type2 <- "synonymous variant" # Fixed variant type2
# Initialize an empty data frame to store results
all_variant_ratios <- data.frame()
for (variant_type1 in variant_types) {
# Filter and calculate dnds for observed mutations
variant.obs <- df %>%
filter(variant_type %in% c(variant_type1, variant_type2)) %>%
select(sample, variant_type, obs.mut) %>%
mutate(obs.mut = obs.mut + 1) %>%
spread(key = variant_type, value = obs.mut, fill = 1) %>%  # fill = 1 to handle cases with 0 count
mutate(dnds.obs = log2(!!sym(variant_type1)/ !!sym(variant_type2)))
# Filter and calculate dnds for simulated mutations
variant.sim <- df %>%
filter(variant_type %in% c(variant_type1, variant_type2)) %>%
select(sample, variant_type, sim.mut) %>%
mutate(sim.mut = sim.mut + 1) %>%
spread(key = variant_type, value = sim.mut, fill = 1) %>%
mutate(dnds.sim = log2(!!sym(variant_type1)/ !!sym(variant_type2)))
# Calculate the observed/simulated ratio
variant.ratio <- variant.obs
colnames(variant.ratio)[2] <- "nonsynonymous variant"
variant.ratio$dnds.sim <- variant.sim$dnds.sim
variant.ratio$dnds.ratio <- variant.ratio$dnds.obs - variant.ratio$dnds.sim
variant.ratio$variant_type <- variant_type1  # Add column to indicate the current variant type
# Combine results of this variant type with the results of previous ones
all_variant_ratios <- rbind(all_variant_ratios, variant.ratio)
}
# Combine with meta data
all_variant_ratios <- merge(all_variant_ratios, sample_table, by = "sample")
return(all_variant_ratios)
}
ratio_significance_dnds <- function(combined_regions, group_vars, group_levels, variable){
results <- combined_regions %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(
p_value = wilcox.test(x = !!sym(variable), mu = 0, exact = FALSE)$p.value
) %>%
ungroup() %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)
)
# Order by region
results$variant_type <- factor(results$variant_type, levels = group_levels)
return(results)
}
group_significance_dnds <- function(combined_regions, group_vars, condition, group_levels, variable){
formula <- as.formula(paste(variable, " ~", condition))
results <- combined_regions %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(
p_value = wilcox.test(formula = formula,
data = cur_data(),
exact = FALSE)$p.value
) %>%
ungroup() %>%
mutate(p_adjusted = p.adjust(p_value, method = "BH"),
significant_p_adjusted = case_when(
p_adjusted <= 0.0001 ~ '****',
p_adjusted <= 0.001 ~ '***',
p_adjusted <= 0.01 ~ '**',
p_adjusted <= 0.05 ~ '*',
TRUE ~ NA_character_)
)
# Order by region
results$variant_type <- factor(results$variant_type, levels = group_levels)
return(results)
}
calculate_stat_summary <- function(observed, group_vars, mut_var){
results <- observed %>%
group_by_at(vars(one_of(group_vars))) %>%
summarise(mean = mean(!!sym(mut_var), na.rm = TRUE),
sd = sd(!!sym(mut_var), na.rm = TRUE))
}
theme_Publication <- function(base_size=16, base_family="helvetica") {
library(grid)
library(ggthemes)
(theme_foundation(base_size=base_size, base_family = "")
+ theme(plot.title = element_text(face = "bold",
size = rel(1.2), hjust = 0.5),
text = element_text(),
panel.background = element_rect(colour = NA),
plot.background = element_rect(colour = NA),
panel.border = element_rect(colour = NA),
axis.title = element_text(face = "bold",size = rel(1)),
axis.title.y = element_text(angle=90,vjust =2),
axis.title.x = element_text(vjust = -0.2),
axis.text = element_text(),
axis.line = element_line(colour="black"),
axis.ticks = element_line(),
panel.grid.major = element_line(colour="#f0f0f0"),
panel.grid.minor = element_blank(),
legend.key = element_rect(colour = NA),
legend.position = "bottom",
legend.direction = "horizontal",
#legend.key.size= unit(0.2, "cm"),
legend.margin = unit(0, "cm"),
legend.title = element_text(face="italic"),
plot.margin=unit(c(10,5,5,5),"mm"),
strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
strip.text = element_text(face="bold")
))
}
scale_fill_Publication <- function(...){
library(scales)
discrete_scale("fill","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
scale_fill_Publication_2 <- function(...){
library(scales)
discrete_scale("fill","Publication",manual_pal(values = c("#7fc97f","#ef3b2c","#386cb0","#fdb462","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
scale_colour_Publication <- function(...){
library(scales)
discrete_scale("colour","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)
}
wrap_labels <- function(labels, width = 5) {
wrapped_labels <- str_wrap(labels, width)
names(wrapped_labels) <- names(labels)
return(wrapped_labels)
}
# Chunk 4
sample_table <- read.table("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/1-data/sample_table_filtered.txt", header = TRUE, sep = "\t")
# Chunk 5
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/5-variant-effect-prediction/1-calculate-ratio")
# consequences
consequences.main.mean <- read.csv("consequence_main_oe_mean.csv", header = TRUE, row.names = NULL)
consequences.main.median <- read.csv("consequence_main_oe_median.csv", header = TRUE, row.names = NULL)
# consequences.sub.mean <- read.csv("observed_consequence_subtypes_ratio_mean.csv", header = TRUE, row.names = NULL)
# consequences.sub.median <- read.csv("observed_consequence_subtypes_ratio_median.csv", header = TRUE, row.names = NULL)
consequences.syn_non.mean <- read.csv("consequence_synonymous_nonsynonymous_oe_mean.csv", header = TRUE, row.names = NULL)
consequences.syn_non.median <- read.csv("consequence_synonymous_nonsynonymous_oe_median.csv", header = TRUE, row.names = NULL)
# alpha missense - score above 0.564 likely pathogenic. range 0-Inf
# use absolute
# am.mean <- read.csv("observed_alpha-missense_absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# am.median <- read.csv("observed_alpha-missense_absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# am.sum <- read.csv("observed_alpha-missense_absolute_ratio_sum.csv", header = TRUE, row.names = NULL)
# cadd - observed variant has negative values while simulated variant has positive values - more positive more damaging
# need to redo and classify into observed and simulated and then count
# classify into insertion and deletion
# use non-absolute
cadd.phred.mean.score <- read.csv("observed_cadd_phred_mean.csv", header = TRUE, row.names = NULL)
cadd.phred.mean <- read.csv("cadd_phred_oe_mean.csv", header = TRUE, row.names = NULL)
cadd.phred.bin.mean <- read.csv("cadd_phred_bin_oe_mean.csv", header = TRUE, row.names = NULL)
cadd.phred.coding.combined.bin.mean <- read.csv("cadd_phred_bin_coding_combined_oe_mean.csv", header = TRUE, row.names = NULL)
# gerp - score above 2 indicates constrained site. Range from -12 to 6
# need to redo and classify into constrained and non and then count
# also need to prevent NA in control when calculating ratio
# use non-absolute and mean
# gerp.mean <- read.csv("observed_gerp_non-absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# gerp.median <- read.csv("observed_gerp_non-absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# transcription factor score change
# use absolute
# tf.mean <- read.csv("observed_tf_absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# tf.median <- read.csv("observed_tf_absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# tf.sum <- read.csv("observed_tf_absolute_ratio_sum.csv", header = TRUE, row.names = NULL)
# phyloP - conserved sites are positive and non-conserved are negative
# need to redo and classify into conserved and non-conserved and then count
# use non-absolute
# phylop.mean <- read.csv("observed_phylop_non-absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# phylop.median <- read.csv("observed_phylop_non-absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# phastcons - probability of negative selection from 0-1
# use non-absolute
# phastcons.mean <- read.csv("observed_phastCons_non-absolute_ratio_mean.csv", header = TRUE, row.names = NULL)
# phastcons.median <- read.csv("observed_phastCons_non-absolute_ratio_median.csv", header = TRUE, row.names = NULL)
# phastcons.sum <- read.csv("observed_phastCons_non-absolute_ratio_sum.csv", header = TRUE, row.names = NULL)
dir.create("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/5-variant-effect-prediction/2-ratio-plot/consequences/cycle/synonymous_nonsynonymous")
setwd("/Users/ronaldcutler/Dropbox\ (EinsteinMed)/Vijg-lab/Projects/mutation\ accumulation/231009\ multiple\ ENU\ analysis/5-variant-effect-prediction/2-ratio-plot/consequences/cycle/synonymous_nonsynonymous")
# add meta data
consequences.syn_non.mean <- merge(consequences.syn_non.mean,
sample_table,
by = "sample")
consequences.syn_non.mean
write.csv(consequences.syn_non.mean,
"consequences.syn_non.mean.csv"
row.names = FALSE)
write.csv(consequences.syn_non.mean,
"consequences.syn_non.mean.csv",
row.names = FALSE)
consequences.syn_non.median <- merge(consequences.syn_non.median,
sample_table,
by = "sample")
write.csv(consequences.syn_non.median,
"consequences.syn_non.median.csv",
row.names = FALSE)
